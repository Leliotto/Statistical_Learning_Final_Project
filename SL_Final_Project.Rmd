---
title: "SL_Final_Project"
author: "Davide Fabio"
date: "2025-04-23"
output:
  pdf_document:
    fig_width: 4
    fig_height: 2.5
  html_document:
    df_print: paged
  word_document: default
  html_notebook: default
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
# Opzioni globali per knitr
knitr::opts_chunk$set(echo = FALSE, results = 'show')
# knitr::opts_chunk$set(fig.width=3.5, fig.height=2)
knitr::opts_chunk$set(fig.align = 'center')

```

```{r}
library(ggplot2)
library(dplyr)

diabetes <- read.csv("diabetes.csv", header = TRUE) # dobbiamo tenerli tutti altrimenti perdiamo 2/3 del dataset
diabetes$gender <- factor(diabetes$gender, levels = c("male", "female"), labels = c("male", "female"))
diabetes$location <- factor(diabetes$location, levels = c("Buckingham", "Louisa"), labels = c("Buckingham", "Louisa"))
diabetes$frame <- factor(diabetes$frame, levels = c("small", "medium", "large"), labels = c("small", "medium", "large"))
diabetes$id <- NULL

diabetes$bmi <- (diabetes$weight*0.453592)/((diabetes$height*0.0254)^2)

# Aggiungi la colonna target (1 se glyhb >= 7.0, 0 altrimenti)
diabetes$diagnosis <- ifelse(diabetes$glyhb >= 7.0, 1, 0)

# Converti in fattore (utile per la classificazione)
diabetes$diagnosis <- as.factor(diabetes$diagnosis)
  
```

```{r}
# standardizzare secondo il massimo di colonna.
# oppure Z-score
# analisi univariata
# analisi bivariata
# rimozione missings
num_vars <- diabetes %>% select(where(is.numeric)) %>% names()
factor_vars <- c("gender", "frame", "location")

for (f in factor_vars) {
  for (n in num_vars) {
    p <- ggplot(diabetes, aes_string(x = f, y = n)) +
      geom_boxplot(fill = "#69b3a2", alpha = 0.7) +
      theme_minimal() +
      labs(title = paste("Distribuzione di", n, "per", f),
           x = f, y = n)
    print(p)
  }
}
```
```{r}
library(dplyr)   # Per la manipolazione dei dati

set.seed(123)

# 1. Conversione delle colonne categoriche in fattori
diabetes <- diabetes %>%
  mutate(
    gender = as.factor(gender),
    location = as.factor(location),
    frame = as.factor(frame)
  )

## 1. Sostituisci bp.2* mancanti con bp.1*
diabetes <- diabetes %>% 
  mutate(
    bp.2s_filled = if_else(is.na(bp.2s), bp.1s, bp.2s),
    bp.2d_filled = if_else(is.na(bp.2d), bp.1d, bp.2d)
  )

## 2. Calcola le medie
diabetes <- diabetes %>% 
  mutate(
    bp.s_mean = round((bp.1s + bp.2s_filled) / 2),
    bp.d_mean = round((bp.1d + bp.2d_filled) / 2)
  )

## 3. (Opzionale) rimuovi le colonne intermedie
diabetes <- diabetes %>% 
  select(-bp.2s_filled, -bp.2d_filled)

## Controllo rapido
summary(select(diabetes, bp.1s, bp.2s, bp.s_mean, bp.1d, bp.2d, bp.d_mean))

diabetes_clean <- diabetes %>% 
  # conserva solo le righe in cui TUTTE le colonne tranne altri non hanno NA
  filter(
    if_all(-c(location, hip, age, height, weight, frame, gender, waist, bp.2s, bp.2d, time.ppn), ~ !is.na(.x))
  )

df_model <- diabetes_clean %>%
  select(
    chol,
    stab.glu,
    hdl,
    ratio,
    bmi,
    bp.s_mean,
    bp.d_mean,
    diagnosis
  )

write.csv(diabetes_clean, "diabetes_clean.csv")
write.csv(df_model, "diabetes_megapulito.csv")

```


```{r}
# Carica le librerie necessarie
library(caret)
library(dplyr)
library(pROC)

# 1. Shuffle del dataset (mescola le righe)
set.seed(123)  # Per riproducibilità
df_model_shuffled <- df_model %>% 
  sample_frac(size = 1, replace = FALSE)  # Mescola senza ripetizioni

# 2. Split in TRAIN (80%) e TEST (20%) stratificato
train_index <- createDataPartition(
  df_model_shuffled$diagnosis,
  p = 0.8, 
  list = FALSE
)
train_data <- df_model_shuffled[train_index, ]
test_data <- df_model_shuffled[-train_index, ]

# 3. Configura la K-Fold Cross-Validation (es. 10-fold)
ctrl <- trainControl(
  method = "cv",     # Cross-Validation
  number = 10,       # Numero di fold
  savePredictions = "final",
  classProbs = TRUE,  # Necessario per ROC-AUC
  summaryFunction = twoClassSummary  # Se diabetic è factor con livelli "0"/"1"
)

# 4. Addestra il modello con K-Fold e Regressione Logistica
# Nota: Converti 'diabetic' in factor con livelli validi per caret
train_data$diagnosis <- make.names(train_data$diagnosis)  # Converti in "X0"/"X1"

logit_model <- train(
  diagnosis ~     chol + stab.glu + hdl + ratio + bmi + bp.s_mean + bp.d_mean,
  data = train_data,
  method = "glm",        # Regressione Logistica
  family = "binomial",   # Famiglia per classificazione
  trControl = ctrl,
  preProcess = c("center", "scale"),  # Normalizza le variabili
  metric = "ROC"         # Ottimizza per l'AUC
)

# 5. Valutazione sul Test Set
# Prepara il test set
test_data$diagnosis <- make.names(test_data$diagnosis)  # Stessa conversione del training

# Predizioni
test_pred <- predict(logit_model, newdata = test_data)
test_prob <- predict(logit_model, newdata = test_data, type = "prob")[, "X1"]  # Probabilità per classe "1"

# Matrice di confusione
confusionMatrix(
  test_pred,
  test_data$diagnosis,
  positive = "X1"  # Specifica la classe positiva (diabetici)
)

# ROC-AUC
roc_obj <- roc(
  response = as.numeric(test_data$diagnosis == "X1"),
  predictor = test_prob
)
plot(roc_obj, main = "ROC Curve")
auc(roc_obj)

# 6. Output del modello finale
summary(logit_model$finalModel)  # Coefficienti e p-value
varImp(logit_model)             # Importanza delle variabili
```

```{r}
# Carica le librerie necessarie
library(mice)    # Per l'imputazione multivariata (MICE)

# Definisci i metodi per colonna
method <- rep("pmm", ncol(diabetes))
method[colnames(diabetes) == "gender"] <- "logreg"
method[colnames(diabetes) == "location"] <- "polyreg"
method[colnames(diabetes) == "frame"] <- "polr"

imputed_data <- mice(
  diabetes,   # Esclude la prima colonna (id)
  m = 5,
  method = method,  # Predictive Mean Matching (adatto per dati numerici e categorici)
  maxit = 15
)

# 3. Estrai il dataset completo
complete_df <- complete(imputed_data)
complete_df

write.csv(complete_df, "diabetes_mice.csv")

```
